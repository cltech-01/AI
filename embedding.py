import os
from pathlib import Path
from dotenv import load_dotenv
from common import measure_time
from langchain_core.documents import Document
from langchain_openai import AzureOpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import PointStruct, Distance, VectorParams
from azure.core.credentials import AzureKeyCredential
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import uuid

# â”€â”€â”€ í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_KEY      = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_DEPLOY   = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
AZURE_VERSION  = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")

# â”€â”€â”€ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
embeddings = AzureOpenAIEmbeddings(
    model = AZURE_DEPLOY,
    openai_api_version=AZURE_VERSION,  # í•„ìš” ì‹œ ì ì ˆí•œ ë²„ì „ìœ¼ë¡œ êµì²´
    api_key=AZURE_KEY,
    azure_endpoint=AZURE_ENDPOINT,
)

# Qdrant í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
qdrant_client = QdrantClient("localhost", port=6333)

qdrant_client.recreate_collection(
    collection_name="meeting_summaries",
    vectors_config=models.VectorParams(
        size=3072,
        distance=models.Distance.COSINE,
        on_disk=True
    ),
    hnsw_config=models.HnswConfigDiff(
        m=32,
        ef_construct=128,
    ),
    quantization_config=models.ScalarQuantization(
        scalar=models.ScalarQuantizationConfig(
            type=models.ScalarType.INT8,
            quantile=0.99,
            always_ram=True,
        )
    )
)

vector_store = QdrantVectorStore(
    client=qdrant_client,
    collection_name="meeting_summaries",
    embedding=embeddings
)

### Text íŒŒì¼ì„ Chunking í•œ í›„ Document List ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
def chunk_text_to_documents(text_path: str, chunk_size: int = 1000, chunk_overlap: int = 50) -> list:
    ext = Path(text_path).suffix

    try:
        with open(text_path, "r", encoding="utf-8") as f:
            full_text = f.read()
    except Exception as e:
        print(f"âŒ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        raise

    # í…ìŠ¤íŠ¸ ì²­í‚¹
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )

    chunks = text_splitter.split_text(full_text)
    print(f"âœ… í…ìŠ¤íŠ¸ ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")

    # Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    source_name = Path(text_path).stem
    docs = [
        Document(
            page_content=chunk,
            metadata={
                "source": source_name,
                "chunk_index": i
            }
        )
        for i, chunk in enumerate(chunks)
    ]

    return docs


# í˜„ì¬ëŠ” FAISS ë¡œ ì„ë² ë”© ì¤‘ì¸ë° ì´ê²ƒì„ qdrantë¡œ ë°”ê¿”ì£¼ë©´ ë©ë‹ˆë‹¤.
@measure_time
def vector_embedding(text_path: str, username: str, openai_api_key: str = None):
    """
    1) í…ìŠ¤íŠ¸ íŒŒì¼ ì²­í‚¹
    2) Azure OpenAIë¡œ ì„ë² ë”©
    3) Qdrantì— Upsert

    Args:
        text_path: í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        username: ì‚¬ìš©ì ì´ë¦„
        openai_api_key: OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ì§€ ì•Šì„ ê²½ìš°)

    Returns:
        ìƒì„±ëœ ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ
    """

    # í…ìŠ¤íŠ¸ íŒŒì¼ ì²­í‚¹ ë° Document ìƒì„±
    print(f'ğŸ”„ í…ìŠ¤íŠ¸ íŒŒì¼ ì²­í‚¹ ì‹œì‘: {text_path} ')
    docs = chunk_text_to_documents(text_path)
    texts = [d.page_content for d in docs]

    # ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    print(f"ğŸ”„ ë²¡í„° ì„ë² ë”© ì‹œì‘: {len(docs)}ê°œ ë¬¸ì„œ")
    vector_store.add_documents(docs)

    print(f"âœ… ë²¡í„° ì„ë² ë”© ì €ì¥ ì™„ë£Œ")
    return vector_store

if __name__ == "__main__":
    print(vector_embedding("./reference/cleaned_example.txt", "jhkim"))
    # docs = chunk_text_to_documents("./Data/Sound/jhkim/01_transcript.txt")
    # print(docs)
