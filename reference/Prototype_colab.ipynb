{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "STT를 위한 whisper모델을 미리 다운을 받고, 실행시키기 위해 빌드합니다.  \n",
        "GPU 쓰고싶으면 런타임구성에서 T4쓰시면 됩니당"
      ],
      "metadata": {
        "id": "X6HIvN41MhBe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FsBGri_eJxEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66f0e91-5530-4844-fdad-aaf9b704e943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Cloning into 'whisper.cpp'...\n",
            "remote: Enumerating objects: 17408, done.\u001b[K\n",
            "remote: Counting objects: 100% (459/459), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 17408 (delta 310), reused 246 (delta 246), pack-reused 16949 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17408/17408), 20.63 MiB | 7.95 MiB/s, done.\n",
            "Resolving deltas: 100% (11952/11952), done.\n",
            "/content/whisper.cpp\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.5.82\")\n",
            "-- CUDA Toolkit found\n",
            "-- Using CUDA architectures: native\n",
            "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "\u001b[0m-- CUDA host compiler is GNU 11.4.0\n",
            "\u001b[0m\n",
            "-- Including CUDA backend\n",
            "-- Configuring done (11.7s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/whisper.cpp/build\n",
            "[  0%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32m\u001b[1mLinking CXX shared library libggml-base.so\u001b[0m\n",
            "[  6%] Built target ggml-base\n",
            "[  7%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o\u001b[0m\n",
            "[ 73%] \u001b[32m\u001b[1mLinking CUDA shared library libggml-cuda.so\u001b[0m\n",
            "[ 73%] Built target ggml-cuda\n",
            "[ 74%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-aarch64.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-hbm.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-quants.c.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu-traits.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX shared library libggml-cpu.so\u001b[0m\n",
            "[ 83%] Built target ggml-cpu\n",
            "[ 84%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX shared library libggml.so\u001b[0m\n",
            "[ 85%] Built target ggml\n",
            "[ 86%] \u001b[32mBuilding CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX shared library libwhisper.so\u001b[0m\n",
            "[ 87%] Built target whisper\n",
            "[ 88%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-whisper.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "[ 91%] Built target common\n",
            "[ 92%] \u001b[32mBuilding CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-cli\u001b[0m\n",
            "[ 93%] Built target whisper-cli\n",
            "[ 94%] \u001b[32mBuilding CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-bench\u001b[0m\n",
            "[ 94%] Built target whisper-bench\n",
            "[ 95%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-server\u001b[0m\n",
            "[ 96%] Built target whisper-server\n",
            "[ 96%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/quantize\u001b[0m\n",
            "[ 97%] Built target quantize\n",
            "[ 98%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/main\u001b[0m\n",
            "[ 99%] Built target main\n",
            "[ 99%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/bench\u001b[0m\n",
            "[100%] Built target bench\n",
            "/content\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "# 📦 필수 패키지 설치\n",
        "!apt-get install -y build-essential cmake ffmpeg\n",
        "\n",
        "# 📥 whisper.cpp 클론\n",
        "!git clone https://github.com/ggerganov/whisper.cpp.git\n",
        "\n",
        "# 📁 디렉토리 이동\n",
        "%cd whisper.cpp\n",
        "\n",
        "# # 🔨 CMake로 빌드 M4 맥북에서 CPU로 돌려볼려면 이거 써주세용\n",
        "# !cmake -B build\n",
        "# !cmake --build build --config Release\n",
        "\n",
        "# 🔨 CUDA 활성화 빌드 # 코랩으로 할려니 너무오래걸려서 잠시 GPU 쓰겠음\n",
        "# M4 맥북 [stt시간 4분? ]\n",
        "# Colab CPU - 너무오래걸림\n",
        "!cmake -B build -DGGML_CUDA=1\n",
        "!cmake --build build --config Release\n",
        "\n",
        "# 다시 디렉토리 밖으로 이동\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영상 전처리를 위한 ffmpeg을 다운로드합니다."
      ],
      "metadata": {
        "id": "EBIheBd2MsI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu 세팅 잘되있나 확인\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEkaV30zRbKt",
        "outputId": "7a190c78-6c3b-455e-eca2-4dfc8c788b9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 19 18:49:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              8W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ml_UHyr5TtMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74c7ff6-f7d4-4d3d-bf5b-054d8de536de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'ffmpeg' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "--2025-04-19 18:49:24--  https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz\n",
            "Resolving johnvansickle.com (johnvansickle.com)... 107.180.57.212\n",
            "Connecting to johnvansickle.com (johnvansickle.com)|107.180.57.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41888096 (40M) [application/x-xz]\n",
            "Saving to: ‘ffmpeg-release-amd64-static.tar.xz’\n",
            "\n",
            "ffmpeg-release-amd6 100%[===================>]  39.95M  14.8MB/s    in 2.7s    \n",
            "\n",
            "2025-04-19 18:49:28 (14.8 MB/s) - ‘ffmpeg-release-amd64-static.tar.xz’ saved [41888096/41888096]\n",
            "\n",
            "📦 ffmpeg dir: ffmpeg-7.0.2-amd64-static\n",
            "ffmpeg version 7.0.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2024 the FFmpeg developers\n",
            "built with gcc 8 (Debian 8.3.0-6)\n",
            "configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
            "libavutil      59.  8.100 / 59.  8.100\n",
            "libavcodec     61.  3.100 / 61.  3.100\n",
            "libavformat    61.  1.100 / 61.  1.100\n",
            "libavdevice    61.  1.100 / 61.  1.100\n",
            "libavfilter    10.  1.100 / 10.  1.100\n",
            "libswscale      8.  1.100 /  8.  1.100\n",
            "libswresample   5.  1.100 /  5.  1.100\n",
            "libpostproc    58.  1.100 / 58.  1.100\n"
          ]
        }
      ],
      "source": [
        " # 기존 ffmpeg 제거 (선택)\n",
        "!apt-get remove ffmpeg -y\n",
        "\n",
        "# 최신 ffmpeg 바이너리 다운로드 (from John Van Sickle build)\n",
        "!wget -O ffmpeg-release-amd64-static.tar.xz https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz\n",
        "\n",
        "# 압축 해제\n",
        "!tar -xf ffmpeg-release-amd64-static.tar.xz\n",
        "\n",
        "# ffmpeg 폴더 이름 찾기 (보통 ffmpeg-6.0-... 식)\n",
        "import os\n",
        "ffmpeg_dir = [d for d in os.listdir() if d.startswith(\"ffmpeg\") and os.path.isdir(d)][0]\n",
        "print(\"📦 ffmpeg dir:\", ffmpeg_dir)\n",
        "\n",
        "# 심볼릭 링크로 경로 등록\n",
        "!cp ./{ffmpeg_dir}/ffmpeg /usr/local/bin/ffmpeg\n",
        "!cp ./{ffmpeg_dir}/ffprobe /usr/local/bin/ffprobe\n",
        "\n",
        "# 확인\n",
        "!ffmpeg -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOAHlpjDN6fC",
        "outputId": "5ae3a5ff-6ad7-40a0-cfc7-b019aabc08dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.53 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "Successfully installed langchain-core-0.3.54 langchain-openai-0.3.14 tiktoken-0.9.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install -U langchain-openai\n",
        "!pip install -U faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0Jj7bCS6DK-m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import gdown\n",
        "import shutil\n",
        "import subprocess\n",
        "from getpass import getpass\n",
        "from langchain.chains import RetrievalQA\n",
        "from huggingface_hub import hf_hub_download\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "whisper 모델중 ggml-small 모델을 사용합니다.\n",
        "tiny는 조금 빠르지만, 성능이 안좋고,,, small이 그나마 성능좋고 빠른정도?"
      ],
      "metadata": {
        "id": "TlC1gj31Mv4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXEfdwMACpk3",
        "outputId": "ebb62914-87e1-4661-a25d-a8d71cb1aba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 다운로드 완료 : /root/.cache/huggingface/hub/models--ggerganov--whisper.cpp/snapshots/5359861c739e955e79d9a303bcbc70fb988958b1/ggml-small.bin\n"
          ]
        }
      ],
      "source": [
        "# 파일 이름 설정\n",
        "LECTURE_FILE_NAME = \"01\"\n",
        "MODEL_NAME = \"ggml-small.bin\"\n",
        "\n",
        "os.makedirs(\"./AX_Data\", exist_ok=True)\n",
        "os.makedirs(f\"./Sound/{LECTURE_FILE_NAME}\", exist_ok=True)\n",
        "os.makedirs(f\"./Text/{LECTURE_FILE_NAME}\", exist_ok=True)\n",
        "\n",
        "# 🔽 모델 다운로드\n",
        "MODEL_PATH = hf_hub_download(\n",
        "    repo_id=\"ggerganov/whisper.cpp\",\n",
        "    filename=MODEL_NAME\n",
        ")\n",
        "print(f\"모델 다운로드 완료 : {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선임님의 강의영상을 다운로드합니다."
      ],
      "metadata": {
        "id": "xnj6bp4EM6Fs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcln8-SHGVpJ",
        "outputId": "af74bcbd-3989-4c25-9a49-202e8f7fe906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1h9lxMPkahHB-dn7p4QBXkMwOZpgVaoSB\n",
            "From (redirected): https://drive.google.com/uc?id=1h9lxMPkahHB-dn7p4QBXkMwOZpgVaoSB&confirm=t&uuid=dbd7b2ee-287c-4bf1-8360-b3f5a9c6cee2\n",
            "To: /content/AX_Data/01.mp4\n",
            "100%|██████████| 495M/495M [00:07<00:00, 62.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 영상 다운로드 완료: ./AX_Data/01.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "video_path = f\"./AX_Data/{LECTURE_FILE_NAME}.mp4\"\n",
        "# Google Drive에서 영상 다운로드\n",
        "file_id = \"1h9lxMPkahHB-dn7p4QBXkMwOZpgVaoSB\"  # Google Drive 공유 링크에서 file_id 추출\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# 다운로드\n",
        "gdown.download(url, video_path, quiet=False)\n",
        "\n",
        "print(f\"✅ 영상 다운로드 완료: {video_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ffmpeg을 이용하여 영상-> 소리를 추출합니다.   \n",
        "다만 4시간을 그대로 소리로 추출하기에 너무 용량이 크기에 silent 처리되는 소리 (영상중간의 무음)  \n",
        "은 제거하여 83분 분량의 길이로 줄입니다.  \n",
        "\n",
        "여기에서 2분단위로 자르는 이유는 whisper 모델이 auto-regressive 구조기에\n",
        "긴 소리의 경우, 동일한 대답만을 반복하는 에러를 return 하기에 2분단위로 잘라서 ffmpeg으로 저장합니다.\n",
        "\n",
        "추가로 m4 맥북에서는 4분정도밖에 안걸리는데 colab환경에서는 오래걸림."
      ],
      "metadata": {
        "id": "FWSHwWtKM9eG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TiT_Vu6Gc3j",
        "outputId": "26a5f951-b86a-4542-f5c1-f562f0252296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 무음 제거 + 2분 자르기 한 번에 완료\n"
          ]
        }
      ],
      "source": [
        "chunk_output_dir = f\"./Sound/{LECTURE_FILE_NAME}\"\n",
        "\n",
        "os.system(\n",
        "    f\"ffmpeg -y -i {video_path} \"\n",
        "    f\"-vn -ar 16000 -ac 1 \"\n",
        "    f\"-af silenceremove=start_periods=1:start_duration=1:start_threshold=-45dB:\"\n",
        "    f\"stop_periods=-1:stop_duration=1:stop_threshold=-45dB,\"\n",
        "    f\"aresample=async=1 \"\n",
        "    f\"-f segment -segment_time 120 -c:a pcm_s16le \"\n",
        "    f\"{chunk_output_dir}/chunk_%03d.wav\"\n",
        ")\n",
        "\n",
        "print(\"✅ 무음 제거 + 2분 자르기 한 번에 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STT를 진행하기 위한 함수를 작성합니다."
      ],
      "metadata": {
        "id": "JsNvAfIONIb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FXFv05HzGqBE"
      },
      "outputs": [],
      "source": [
        "def whisper_cpp_transcribe(file_name, model_name):\n",
        "    model_label = model_name.replace(\".bin\", \"\")\n",
        "    audio_path = f\"./Sound/{LECTURE_FILE_NAME}/{file_name}.wav\"\n",
        "    output_file_prefix = f\"./Text/{LECTURE_FILE_NAME}/{file_name}_{model_label}\"\n",
        "\n",
        "    os.makedirs(f\"./Text/{LECTURE_FILE_NAME}\", exist_ok=True)\n",
        "\n",
        "    cmd = [\n",
        "        \"./whisper.cpp/build/bin/whisper-cli\",\n",
        "        \"-m\", MODEL_PATH,\n",
        "        \"-f\", audio_path,\n",
        "        \"-l\", \"ko\",\n",
        "        \"-oj\",\n",
        "        \"-of\", output_file_prefix,\n",
        "    ]\n",
        "\n",
        "    subprocess.run(cmd)\n",
        "    print(f\"✅ {file_name} 처리 완료 → {output_file_prefix}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVtS5D7yJf7z",
        "outputId": "62895509-324a-43fb-99ac-0283a32d1ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 chunk count: 42\n",
            "🎵 chunk files: ['chunk_000.wav', 'chunk_001.wav', 'chunk_002.wav', 'chunk_003.wav', 'chunk_004.wav'] ...\n",
            "✅ chunk_000 처리 완료 → ./Text/chunk_000_ggml-small.json\n",
            "✅ chunk_001 처리 완료 → ./Text/chunk_001_ggml-small.json\n",
            "✅ chunk_002 처리 완료 → ./Text/chunk_002_ggml-small.json\n",
            "✅ chunk_003 처리 완료 → ./Text/chunk_003_ggml-small.json\n",
            "✅ chunk_004 처리 완료 → ./Text/chunk_004_ggml-small.json\n",
            "✅ chunk_005 처리 완료 → ./Text/chunk_005_ggml-small.json\n",
            "✅ chunk_006 처리 완료 → ./Text/chunk_006_ggml-small.json\n",
            "✅ chunk_007 처리 완료 → ./Text/chunk_007_ggml-small.json\n",
            "✅ chunk_008 처리 완료 → ./Text/chunk_008_ggml-small.json\n",
            "✅ chunk_009 처리 완료 → ./Text/chunk_009_ggml-small.json\n",
            "✅ chunk_010 처리 완료 → ./Text/chunk_010_ggml-small.json\n",
            "✅ chunk_011 처리 완료 → ./Text/chunk_011_ggml-small.json\n",
            "✅ chunk_012 처리 완료 → ./Text/chunk_012_ggml-small.json\n",
            "✅ chunk_013 처리 완료 → ./Text/chunk_013_ggml-small.json\n",
            "✅ chunk_014 처리 완료 → ./Text/chunk_014_ggml-small.json\n",
            "✅ chunk_015 처리 완료 → ./Text/chunk_015_ggml-small.json\n",
            "✅ chunk_016 처리 완료 → ./Text/chunk_016_ggml-small.json\n",
            "✅ chunk_017 처리 완료 → ./Text/chunk_017_ggml-small.json\n",
            "✅ chunk_018 처리 완료 → ./Text/chunk_018_ggml-small.json\n",
            "✅ chunk_019 처리 완료 → ./Text/chunk_019_ggml-small.json\n",
            "✅ chunk_020 처리 완료 → ./Text/chunk_020_ggml-small.json\n",
            "✅ chunk_021 처리 완료 → ./Text/chunk_021_ggml-small.json\n",
            "✅ chunk_022 처리 완료 → ./Text/chunk_022_ggml-small.json\n",
            "✅ chunk_023 처리 완료 → ./Text/chunk_023_ggml-small.json\n",
            "✅ chunk_024 처리 완료 → ./Text/chunk_024_ggml-small.json\n",
            "✅ chunk_025 처리 완료 → ./Text/chunk_025_ggml-small.json\n",
            "✅ chunk_026 처리 완료 → ./Text/chunk_026_ggml-small.json\n",
            "✅ chunk_027 처리 완료 → ./Text/chunk_027_ggml-small.json\n",
            "✅ chunk_028 처리 완료 → ./Text/chunk_028_ggml-small.json\n",
            "✅ chunk_029 처리 완료 → ./Text/chunk_029_ggml-small.json\n",
            "✅ chunk_030 처리 완료 → ./Text/chunk_030_ggml-small.json\n",
            "✅ chunk_031 처리 완료 → ./Text/chunk_031_ggml-small.json\n",
            "✅ chunk_032 처리 완료 → ./Text/chunk_032_ggml-small.json\n",
            "✅ chunk_033 처리 완료 → ./Text/chunk_033_ggml-small.json\n",
            "✅ chunk_034 처리 완료 → ./Text/chunk_034_ggml-small.json\n",
            "✅ chunk_035 처리 완료 → ./Text/chunk_035_ggml-small.json\n",
            "✅ chunk_036 처리 완료 → ./Text/chunk_036_ggml-small.json\n",
            "✅ chunk_037 처리 완료 → ./Text/chunk_037_ggml-small.json\n",
            "✅ chunk_038 처리 완료 → ./Text/chunk_038_ggml-small.json\n",
            "✅ chunk_039 처리 완료 → ./Text/chunk_039_ggml-small.json\n",
            "✅ chunk_040 처리 완료 → ./Text/chunk_040_ggml-small.json\n",
            "✅ chunk_041 처리 완료 → ./Text/chunk_041_ggml-small.json\n",
            "✅ 전체 병합 완료 → ./Text/01/01_merged_ggml-small.json\n"
          ]
        }
      ],
      "source": [
        "# ✅ .wav 파일만 필터링\n",
        "sound_dir = f\"./Sound/{LECTURE_FILE_NAME}\"\n",
        "chunk_files = sorted([\n",
        "    f for f in os.listdir(sound_dir)\n",
        "    if f.endswith(\".wav\")\n",
        "])\n",
        "\n",
        "chunk_count = len(chunk_files)\n",
        "print(\"📦 chunk count:\", chunk_count)\n",
        "print(\"🎵 chunk files:\", chunk_files[:5], \"...\")\n",
        "\n",
        "# ✅ 병합용 경로 설정\n",
        "model_label = MODEL_NAME.replace(\".bin\", \"\")\n",
        "output_merged_path = f\"./Text/{LECTURE_FILE_NAME}/{LECTURE_FILE_NAME}_merged_{model_label}.json\"\n",
        "merged_segments = []\n",
        "\n",
        "# ✅ 42개의 chunk 처리\n",
        "for i in range(chunk_count):\n",
        "    chunk_id = f\"chunk_{i:03d}\"\n",
        "\n",
        "    # whisper 처리 (여기 함수는 기존 그대로 사용)\n",
        "    whisper_cpp_transcribe(chunk_id, MODEL_NAME)\n",
        "\n",
        "    # 결과 JSON 읽기\n",
        "    json_path = f\"./Text/{LECTURE_FILE_NAME}/{chunk_id}_{model_label}.json\"\n",
        "    if os.path.exists(json_path):\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "            merged_segments.extend(data.get(\"transcription\", []))\n",
        "\n",
        "# ✅ 최종 병합된 JSON 저장\n",
        "with open(output_merged_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"transcription\": merged_segments}, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✅ 전체 병합 완료 → {output_merged_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bh_2IPBVTxcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c1fdf1-0cf9-49b2-de7d-724ced65f3eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'timestamps': {'from': '00:00:00,000', 'to': '00:00:20,980'},\n",
              "  'offsets': {'from': 0, 'to': 20980},\n",
              "  'text': ' (인터뷰)'},\n",
              " {'timestamps': {'from': '00:00:20,980', 'to': '00:00:25,580'},\n",
              "  'offsets': {'from': 20980, 'to': 25580},\n",
              "  'text': ' 혹시 여러분, 젠킨스라는 툴을 해본 적이 있다.'},\n",
              " {'timestamps': {'from': '00:00:25,580', 'to': '00:00:27,580'},\n",
              "  'offsets': {'from': 25580, 'to': 27580},\n",
              "  'text': ' 젠킨스 써본 적 있다.'},\n",
              " {'timestamps': {'from': '00:00:27,580', 'to': '00:00:32,400'},\n",
              "  'offsets': {'from': 27580, 'to': 32400},\n",
              "  'text': ' 써보실 때 어느 정도 쓰시니 까지 써보셨어요.'},\n",
              " {'timestamps': {'from': '00:00:32,400', 'to': '00:00:35,560'},\n",
              "  'offsets': {'from': 32400, 'to': 35560},\n",
              "  'text': ' 그냥 사용자 입장에서 파이프라인이 짜는 정도?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# STEP 1. Whisper JSON 불러오기\n",
        "with open(f\"./Text/{LECTURE_FILE_NAME}/{LECTURE_FILE_NAME}_merged_ggml-small.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "segments = data[\"transcription\"]\n",
        "segments[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HGVnS32PTzi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4f3ba780-541b-401b-c1a5-87ffb87243c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' (인터뷰)\\n 혹시 여러분, 젠킨스라는 툴을 해본 적이 있다.\\n 젠킨스 써본 적 있다.\\n 써보실 때 어느 정도 쓰시니 까지 써보셨어요.\\n 그냥 사용자 입장에서 파이프라인이 짜는 정'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# STEP 2. 전체 텍스트 이어붙이기\n",
        "full_text = \"\\n\".join([seg[\"text\"] for seg in segments])\n",
        "full_text[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000개의 청크 단위로, document를 나눕니다. 나누어진 document는\n",
        "하나당 각 벡터공간으로 embedding 됩니다.\n",
        "\n",
        "이때 1000개 단위로 50개씩 겹쳐서 document를 만듭니다."
      ],
      "metadata": {
        "id": "CSQ5ASn2PU22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vNtqZWTRT0t7"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(full_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tD974y7ST1jS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ed5b19-8d43-4bd8-a087-78df24b8176b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔐 OpenAI API Key를 입력하세요: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"🔐 OpenAI API Key를 입력하세요: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인 메모리 vector database인 FAISS에 임베딩합니다.  \n",
        "(나누어진 도큐먼트들)"
      ],
      "metadata": {
        "id": "1VQcXuo6Pgrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8TxqriExT2ol"
      },
      "outputs": [],
      "source": [
        "# STEP 4. Document 리스트로 변환\n",
        "docs = [Document(page_content=chunk, metadata={}) for chunk in chunks]\n",
        "\n",
        "# STEP 5. Embedding + Vectorstore 생성\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MMR(maximal marginal relevance) 알고리즘을 사용하여\n",
        "중복되는 document를 return하지 않도록 합니다.\n",
        "\n",
        "100개중에 중복되는것들을 다지우고 10개를 남깁니다.\n",
        "\n",
        "추가로 Langchain 대답 return 방식은 Stuffing 방식을 사용합니다."
      ],
      "metadata": {
        "id": "agKbZURoPnKi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8-kqz0xsT3xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432782a6-cc7a-4f22-d318-568ed7567c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-9902a6564352>:10: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm=ChatOpenAI(temperature=0),\n"
          ]
        }
      ],
      "source": [
        "# STEP 6. Retriever + QA Chain 구성\n",
        "retriever = vectorstore.as_retriever(search_type=\"mmr\")\n",
        "retriever.search_kwargs.update({\n",
        "    \"k\": 10,\n",
        "    \"fetch_k\": 100,\n",
        "    \"maximal_marginal_relevance\": True\n",
        "})\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(temperature=0),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트를 한번해봅니다.."
      ],
      "metadata": {
        "id": "nieSnLBvPzw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "agRBrULaT4tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ee0c7f-4472-4832-b40d-bbfef848ee37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💬 Question: 강사님이 강의 전반적으로 강조하시는 부분이 뭐야?\n",
            "🧠 Answer: 강사님은 젠킨스와 관련된 주제를 중점적으로 다루고 계시며, 젠킨스의 기능과 활용 방법에 대해 설명하고 있습니다. 또한 오픈소스 툴과 플러그인을 활용하여 젠킨스를 보다 효율적으로 사용하는 방법에 대해 강조하고 계십니다. 또한 젠킨스를 통한 CI/CD 프로세스와 관련된 내용을 강조하고 있습니다.\n",
            "📄 Source Metadata: [Document(id='53650263-abdf-4096-a9e1-dcd78c6ef9e2', metadata={}, page_content='- 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n - 형님, 이거 안 찍어 봐. - 형님, 이거 안 찍어 봐.\\n 저희 올렸는데 거기서 왜 안 올리니깐 아까 부엉때리기 방함이\\n 7박 4일에 3박 4일 기여서 7박 3일 같다고요?\\n 그쵸 그쵸 그쵸 그정도 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸\\n 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸 그쵸\\n 조금씩 깔을 수 있는데\\n 좀 더 이번엔 7번은 깔을 수 있도록 하겠습니다\\n 한 번 더 깔을 수 있도록 하겠습니다\\n 굉장히 많으니깐\\n 7번 깔을 수 있도록 하겠습니다\\n 한 번 다시 깔을 수 있도록 하겠습니다\\n 다음은 어떻게 써볼까요?\\n 진짜 마지막에 깔을 수 있어요\\n 네, 마지막에 깔을 수 있을까요?\\n 마지막에 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 3번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 5번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?'), Document(id='ae230519-7eab-4152-b799-c2683a028392', metadata={}, page_content='컨테이너들을 하드 형태로 전체적인 관리를 해 줄 수 있게 해주는 이걸\\n 정확히는 어, 오케스트레이션 툴이라고 하거든요. 코버네티스를.\\n 그래서 거기에 대해서 가까이 배포를 할 수 있는 환경이에요. 요즘에는.\\n 근데 요즘 이제 MSA라든가 이런 대규모 서비스를 뭐 이런 거 있죠.\\n 정말 서비스가 너무 다양해서\\n 각각의 기능을 MSA로 구현하는 방식에는\\n 모든 그 프로세스나 서비스를 수동으로 관리하기 어렵기 때문에\\n 코버네티스에 많이 뛰어들고 있고\\n 따라서 그것 때문에 이제 서비스 간의 의전성도 좀 높아지고\\n 여러 가지 문제가 있지만 어쨌든 코버네티스는 좋은 툴입니다.\\n 요즘 워낙 몇 년 전부터 트렌디이기도 하고\\n 여러분들도 잘 아셔서 힘 가셔서 AKS를\\n 다루실 가능성이 높기 때문에 잘 아시면 좋을 것 같고\\n 뭐 각각의 장단점 이런 거 이제 뭐 그냥 간단하게 보시면 돼요.\\n 어, 코버네티스 배포 뭐 매우 빠르다.\\n 왜냐면은 그냥 파드 뭐 이런 오케스트레이션 자체를\\n 코버네티스가 다 잘 해주고 뭐 기도스 같은 툴도 잘 되어 있고\\n 사람들은 그냥 야물 정의해서 아까 말씀 주신 것처럼 기탑 연동해 가지고 그냥\\n 어, 버튼 딱강 누르면 배포 되는 수준이라서 정말 쉽죠.\\n 운영 난이도가 어려운 이유는 코버네티스라는 거 자체가\\n 좀 이해하기 어려운 런닝커브가 있는 어, 오픈 소스예요.\\n 그래서 어, 그렇긴 한데 저희는 기본적으로\\n 사내에서는 배포할 때 디플로이먼트랑 서비스랑 그 정도만 알고 계시면 됩니다.\\n 인그레스 해서 이 사용자들이 어떻게 엔트리 포인트로 들어와서 이 안에 이거를 분산시켜서 꾸려줄지 정도만 이해를 하시면 돼요.\\n 그 외에 여러 가지 그 오버젝트들이 있죠.\\n 데몬셋이라든가 스테이크 풀셋 이렇게 코버리티스의 파드를 다른 형태로 띄워주는 것들은 쓰실 수는 있긴 하지만 사실 잘 쓰고 있는 팁이 있겠죠.\\n 저는 잘 모릅니다. 그래서 기본적인 것만 알고 계시면 됩니다.'), Document(id='24a0a378-7538-4c9f-91d7-87b279fa5f57', metadata={}, page_content='여러분도 한 번씩 로그인 하시는 게 좋을 것 같고\\n 음 네 이렇게 부정되어 있습니다\\n 오늘 그래서 이 아래 얘기는 길진 않아서 이따 오후에다가 잠깐 다시 하고\\n 오늘 여러분들이 RGO CD에 접속을 하셔야 되고\\n 거기에 대한 정보를 제가 여기에 드렸어요\\n 이게 탈의 PC 충전 되시면은\\n 그냥 이 여기 아래에 있는 이 윈도우 3색이 있죠\\n 여기서 그냥 메모작 전색해서\\n 클릭해서 관리자 권한으로 실행하면 이렇게 그냥 빙 메모작 하나 뜨거든요\\n 얘는 관리자 권한으로 실행되어 내고\\n 여기서 이제 열기 파일 열기\\n 해서 이 아래 이제 패스 보시면\\n T드라이브 들어가셔서 Windows 아래, 시스템 32 아래, 드라이버 아래, ETC 아래 딱 들어가면 아무것도 안 보이거든요\\n 근데 이때 오른쪽 아래 모든 파일을 활성하시면 호스트 파일이 있어요\\n 이게 어 우리가 RGO CD를 접속할 때는\\n 인그레스에 있는 호스트 네임으로 들어갈 거예요\\n 저는 이제 URI, URI 형태로 되어 있겠죠\\n 근데 거기에 이제 진입할 우리가 방압의 장업 해놓은 커버네티스 인터널에 콘텐츠 IP 정보를 URI 알고 있지 않아요\\n 그러니까 DNS 등록을 안 해놨습니다\\n 따라서 우리 IP로 들어가야 되는데\\n 거기에 대한 로컬, DNS를 구성하는 방식이라고 생각하시면 됩니다\\n 그러니까 우리가 PC 안에서\\n DNS가 구성되어 있지 않은 URI 요청을 할 때\\n 거기에 대해서 가장 먼저 찾아보는 게 이 호스트 파일이거든요\\n OS에 있는 이 DNS 구성 따라서 여기에다가\\n 아래에 이렇게 넣으시면 돼요 그냥 IP로\\n 위에 꼭 무시해 주시고 제가 쓰는 거로\\n 아랫거 넣고 그 다음에 URI 넣고 그냥 복사 부처는 이렇게 하셔서\\n 버전 하신 다음에 웹 브라우저에 다시 들어가셔서\\n 검색 검색이 아니라 엔터를 누르면 이제 들어가지는 것까지 확인하셔야 돼요\\n -그렇게.\\n 그래서 배터리 충전 좀 해보시고\\n ROGCD 적극하시면 로그인까지 해볼 수 있는 겁니다.\\n 저하고 11시 반에 밥 먹으러 가시면 돼요.\\n 아시겠죠?'), Document(id='4ee30c3d-c4de-4e47-af73-06c1a3bc5ccc', metadata={}, page_content='저하고 11시 반에 밥 먹으러 가시면 돼요.\\n 아시겠죠?\\n. [두 번째 질문]\\n [두 번째 질문]\\n [두 번째 질문]\\n [두 번째 질문]\\n [두 번째 질문]\\n [두 번째 질문]\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데\\n 그 자체수비가 어떻게 생각할지 모르겠는데'), Document(id='17f2850d-c75b-4def-a40b-9791f2a89327', metadata={}, page_content='5번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 4번 깔을 수 있을까요?\\n 오늘 24년 중한테 말씀 사는 분, 홍백이 우리 클 채널에 거기다 남겨줘요. 네. 네. 네. 네. 인생을 부탁드립니다. 안녕하세요.\\n -특근이 참... -네. 네. 영상도 못 찍고 있는데 마이크가 좀 있고 신의 시간에 꽂히면 그걸로 저희가 할 게 있고. 아 그래요? 알겠습니다. 네.\\n -오셨죠? -네. 네. 시작할게요.\\n 제가 사내빛 씨를 가져오러 간 이유는 아르코 시디를 젠키스도 그렇고 아르코 시디도 그렇고 저희가 사내 환경에서 배포를 할 때는 사내빛 씨로 접속을 방압을 뚫어서 하고 있어요.\\n 그래서 지금 간단하게 방압에 대한 정책 얘기를 하고서 그다음에 시디 들어가 보도록 할게요. 우리가 CICT를 하기 위해서는 오늘 이제 여러분들이 실습을 하고자 제가 미리 방압을 뚫어둔 부분도 있어서\\n 그것까지 좀 인지를 하시면 좋을 것 같아요. 첫 번째로 우리가 CICT를 하려면 기텀 액션을 쓰기 위한 방압 순정이 필요합니다.\\n 그래서 우리가 Vmbefo를 할 때 Vmbefo의 경우에는 우리가 CI를 하면 지금껏 계속 얘기했던 정적 파일들이 있죠. 점, 자르, 점, 와, 를 아니면 파이선, 점, 위일 같은 파일들을 블록 스토리지에 올릴 거예요.\\n 블록 스토리지에다가 업로드하는 기체는 러너가 하는 거기 때문에 서비스 팀마다 구성한 블록 스토리지에 대해서 방압을 신청을 직접 하셔야 됩니다.\\n 이거는 저희 팀 해드리는 건 아니고 러너 걸리는 저희가 하지만 방압을 직접 해야 된다.\\n 그래서 Vmbefo의 경우 우리 러너 서버의 로드 밸런스 IP를 여기에 고정해 놨어요. 거기에서 서비스 팀마다 꾸릴 스토리적 카운트의 프라이빗 엔드 포인트 들어보셨나요?'), Document(id='263a789b-6097-4ffd-b5be-000117dc1aa6', metadata={}, page_content=\"복사 부처하시면 되거든요.\\n 그럼 이게 초기 세덕 비밀번호가\\n 이제 프로세스에 남아 있는 거예요.\\n 그래서 이걸로 확인하셔서\\n 넣으시면 저랑 같은 화면이 나올 겁니다.\\n 아마도.\\n 슬러덩이 깔면 됩니다.\\n 그냥 추천해주는 걸로 다 갈아주시면 되겠습니다.\\n 네.\\n 고맙습니다.\\n 괜찮았어. 나 지금...\\n 어디서 왔어? 내가 왔을 때 왔어.\\n 아니 그거를 처음으로 쳐.\\n 아, 이거?\\n 근데 그거 피스는 왜 그러는 거야?\\n 내가 신경쓰는...\\n 신경쓰는...\\n 신경쓰는...\\n 침대인가요?\\n 신경쓰는...\\n 그거라서 좀 더 없는 거죠.\\n 신경쓰는...\\n 신경쓰는...\\n 그거라서 좀 더 없는 거죠.\\n 아, 그런 거네.\\n 신경쓰는...\\n 신경쓰는...\\n 그치. 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n 그거라서 좀 더 없는 거죠.\\n [두 번째 요리는 '두 번째 요리'입니다]\\n - 네. - 네.\\n - 여기 진짜 진짜 잘 찍는 것 같아. - 진짜 잘 찍는 것 같아.\\n - 진짜 잘 찍는 것 같아. - 진짜 잘 찍는 것 같아.\\n - 그래, 그래. - 미쳤어요?\\n - 네, 네. 아, 됐어요? - 여기 찍는 거죠.\\n - 이거 한 번? - 네.\\n - 네, 잘 찍는 거예요. - 네, 잘 찍는 거예요.\\n - 진짜 잘 찍는 거예요. - 진짜 잘 찍는 거예요.\\n - 네, 잘 찍는 거예요. - 네, 잘 찍는 거예요.\\n - 오, 나 이렇게 잘 찍봤어요. - 네, 잘 찍는 거예요.\\n - 네, 잘 찍는 거예요. - 네, 잘 찍는 거예요.\\n - 잘 찍는 거예요. - 네, 잘 찍는 거예요.\\n - 이거 지금? - 응.\\n - 오늘... - 컨셉에서 죽이고 한 거 다시 해볼까?\\n - 한 번 더. - 한 번 더 내리고, 한 번 더 내리고.\\n - 중심 다른 분들은 다 이 화면 나오셨나요? - 아, 됐어요, 됐어요.\"), Document(id='a282592b-4443-479e-84b7-d2453340e5d4', metadata={}, page_content='상용 100%를 하게 되잖아요.\\n 검증되지 않은 어플리피해시는 100% 되면 상의가 될 수도 있어요.\\n 그런 식으로 해서 이제 분리를 해둔 경험이거든요.\\n -아이고시리에서 보낸 건 보안으로 상관 괜찮은 거예요. -아이고시리에는? -뱅키스로 보안이 괜찮아요. 기적 옵션으로 댓글하게돼요. 보안이 좀 운전을 하시네요.\\n 그게 왜냐하면 인터뷰는 우리가 엔터프라이즈로 사스용을 쓰고 있고 지금 이 VMA 젠키스나 아니면 컴테이너의 아르고시리 같은 경우 산해방처럼 구성되어 있는 인바운드는 직접 타기 어려워라. 그래서 히터 맥션에 실행하는 주체가 인바운드로 들어오게 될까?\\n -뱅키스는 산해에서 제공하고 오늘은 시습사와 개발매계 산 거라서 좀 다른데... -뱅키스입니다.\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 아..빠져도 안되지..\\n 우리 3번 비쥬얼이예요, 3번 갈거예요?\\n 3번 비쥬얼, 3번 비쥬얼이예요?\\n 3번 비쥬얼, 3번 갈거예요?\\n 3번 비쥬얼, 3번 갈거예요?\\n 3번 비쥬얼, 3번 갈거예요?\\n 3번 비쥬얼, 3번 갈거예요?\\n 3번 비쥬얼, 3번 갈거예요?'), Document(id='ba426e0d-6e9c-4bb1-b635-0cfa90b7e470', metadata={}, page_content='뒤에 하이폰 기록스만 붙여주세요.\\n 그래요?\\n 그러면 ROCD 하기 전이니까\\n 지금은 개발 맥으로 GTN이 붙으셔가지고\\n 조금 하셔도 될 것 같아요.\\n [두 번째 주인공]\\n 이 텔레임 레지스트리는 어디에 구성해주시는거에요?\\n (댓글 읽는 중)\\n 아 거기에 있어요?\\n (댓글 읽는 중)\\n 알겠습니다.\\n (댓글 읽는 중)\\n 그래서 래퍼 하나씩 만들었거든요.\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)\\n (댓글 읽는 중)'), Document(id='546ade2f-6643-4723-b69f-694d60efc06b', metadata={}, page_content='뭐랄까 사용자들이 많이 쓰고 좀 호환성이 되어 있느냐에 대한 그런 수치예요\\n 그래서 좀 플러그인을 사실 전부 다 오픈소스라서 가져다 쓸 때\\n 이거를 사용할 때 무리가 없으려면 이런 수치를 좀 보는 것도 좋고\\n 또 젠키스 플러그인에서 다른 사람들은 뭐를 많이 쓰고 있을까 좀 궁금하죠\\n 그럼 아래에서 트렌딩 이런 거 있어요\\n 그래서 이 아래에 있는 10개의 플러그인들은 다른 사람들이 많이 쓰는 거거든요\\n 이 중에 하나로 진짜 단순하게 이런 거 있죠 뭐 다크테마 이런 거\\n 젠키스 까맣게 바꿔 주는 거 이런 것도 있고\\n 매트립 확인하는 것도 있네요 그리고 쏘나큐브라고 해서 이제\\n 안에 취약점 검토하는 것들 뭐 이런 호환 관련된 오픈소스도 연동해서 쓰고\\n 빌드타임아웃이라고 해서 잡마다 이제 타임아웃 시간을 세팅한 다음에\\n 쓰는 이런 플러그인도 있네요 이렇게 해서 이제\\n 사실 어 저희 팀에서 공통적으로 이런 표준을 제공해드리긴 하지만\\n 팀마다 모든 커스텀 된 쪽을 이제 다를 수 없기 때문에\\n 이런 식으로 해서 본인의 이 젠키스를 꾸려나갈 수 있다라는 장점이 있습니다\\n 젠키스가 둘이 플러그인이 많아서 그리고 다시 이제 어드민으로 들어와서\\n 뭐가 있을까 시스템 로그 모든 젠키스 로그 이런 거 있네요\\n 젠키스에 대한 모든 로그를 볼 수 있는 이런 거 중요하겠죠\\n 로그보는 거 젠키스에서 뭐 뭔가 문제가 생겼으면 로그를 보면\\n 확확하기 쉬우니까 그래서 이런 로그 보는 것도 있고 네 그렇습니다\\n 그리고 하나 좀 특이한 게 스크립트 콘솔이라고 해서\\n 젠킨스에다가 직접 명령을 내릴 수 있어요.\\n 근데 이 언어는 기본적으로 그루비 언어거든요.\\n 그래서 그루비 같은 경우는 그냥 AI가 더 잘 만들어주니까.\\n 그루비 언어 공부할 수 필요 없이\\n 그냥 젠킨스, 스크립트 콘솔에다가 쓸 이런 명령어를 그루비로 짜달라고 하면 알아서 잘 짜주거든요.\\n 특히 어떨 때 좀 중요하냐면\\n 만약에 우리가 젠킨스를 얼마나 쓰고 있는지 알고 싶다.\\n 근데 만약에 파이프라인이 한 100개예요.'), Document(id='c88797f5-120e-488b-8190-d98c04ced1c5', metadata={}, page_content='뭐 LSS 찍혀서 다운로드 잘 받았는지 볼 수 있겠죠\\n 그럼 또 자바 같은 경우에는\\n 자바 프로세스 띄우는\\n 자바 자를 이런 명령어로\\n 타겟 VM이 본인의 이 배포된 이미지를\\n 아니지 CI 된 이 파일을 배포를 하게 되는 그런 케이스입니다\\n 그래서 이 명령어는 지금 실행은 안 되실 거고\\n 이런 식의 흐름만 이해를 좀 해 주시면 될 것 같아요\\n 케이스 배포 같은 경우는 어렵지 않아서\\n 오늘은 이런 식으로 잡을 꾸리는 것까지만 이제\\n 약간 대모식으로 보여드리겠습니다.\\n 그리고 10시 30분까지 쉬었다가\\n 아로그시디 하기 전에 이론 조금 하고\\n 오후에는 아로그시디 100% 실습을 진행하도록 하겠습니다.\\n 오늘 젠키스 하면서 이해 안 되시는 거 있으셨는데\\n 이게 뭐가 어렵다 라든가.\\n 어디서 뵙고?\\n CIC기로 뵙고 할 때 깁다 맥션으로 그냥 할게요.\\n 어 이거는 장점, 장점 왜 제키스를 쓰냐는 거죠.\\n 우선 저희 산에 보완 정책상\\n 100%를 할 때\\n 지금 이 방금 말씀드린 구조가 젠키스가\\n 하겟 BM에 따라 명령을 내리는 혁우태가\\n 하겟 VM의 저장소에서 긁어오라는 뜻이에요.\\n 이걸 풀 방식이라고 하거든요.\\n 우리가 아로그시디 할 때도 기돕스를 쓰면\\n 기텁에 있는 100% 양식을 아로그시디가 기돕스러 긁어와서\\n ACR에 있는 이미지를 긁어와서 100%를 할 거예요.\\n 이것도 풀 방식이에요.\\n KT에서는 100%를 할 때 풀 방식을 공정하고 있어요.\\n 기본적으로.\\n 그런데 기텁 액션에서 100%를 하게 되면\\n 우선 첫 번째로 기텁 엔터파이즈에서\\n 저희 산에 애정 환경에 인바운드로 직접 찌를 수 없거든요.\\n 애정 안에 있는 VM에다가 직접 넣게 쓸 수 있게 내린다 보니.\\n 그럼 두 번째로\\n 그런 만약에 그게 가능하다 하는 게 아니지.\\n 아니 그게 가장 큰 일이죠.\\n 첫 번째로 인바운드가 안 생각나요.\\n 두 번째로는 치킨스로 따로 분리를 해뒀을 때\\n 어제 이게 또 만약에 CIC를 한 번에 자동화를 해놨을 때\\n 상용 100%를 하게 되잖아요.')]\n"
          ]
        }
      ],
      "source": [
        "# STEP 7. 유저 질문 테스트\n",
        "query = \"강사님이 강의 전반적으로 강조하시는 부분이 뭐야?\"\n",
        "result = qa(query)\n",
        "\n",
        "print(\"💬 Question:\", query)\n",
        "print(\"🧠 Answer:\", result['result'])\n",
        "print(\"📄 Source Metadata:\", result['source_documents'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}